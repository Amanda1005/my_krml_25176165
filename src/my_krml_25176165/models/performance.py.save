from sklearn.metrics import accuracy_score, f1_score

def print_classifier_scores(y_preds, y_actuals, set_name: str) -> None:
    """
    Print Accuracy and F1 score for a given set.
    """
    acc = accuracy_score(y_actuals, y_preds)
    f1  = f1_score(y_actuals, y_preds, average="weighted")
    print(f"[{set_name}] Accuracy: {acc:.4f} | F1: {f1:.4f}")


def assess_classifier_set(model, features, target, set_name: str) -> None:
    """
    Predict with model on given features, then print accuracy & F1.
    """
    y_preds = model.predict(features)
    print_classifier_scores(y_preds, target, set_name)


def fit_assess_classifier(model, X_train, y_train, X_val, y_val) -> None:
    """
    Fit model on training set, then print scores on Train and Validation.
    """
    model.fit(X_train, y_train)
    assess_classifier_set(model, X_train, y_train, "Train")
    assess_classifier_set(model, X_val, y_val, "Validation")
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

def print_regressor_scores(y_preds, y_actuals, set_name="Set"):
    """Print RMSE and MAE for regression predictions."""
    rmse = np.sqrt(mean_squared_error(y_actuals, y_preds))
    mae = mean_absolute_error(y_actuals, y_preds)
    print(f"RMSE {set_name}: {rmse}")
    print(f"MAE {set_name}: {mae}")
